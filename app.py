import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import torch

# Load model with caching
@st.cache_resource
def load_model():
    hf_token = "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"
    model = SentenceTransformer("Chanisorn/thai-food-mpnet-tuned", use_auth_token=hf_token)
    return SentenceTransformer('Chanisorn/thai-food-mpnet-tuned')

# Load CSV data with caching
@st.cache_data
def load_data():
    df = pd.read_csv("Copy of Copy of 500 lable ‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì superclean + ‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏´‡∏ß‡∏≤‡∏ô + query - Sheet1.csv")
    return df

# Compute embeddings once
@st.cache_resource
def embed_corpus(sentences):
    return model.encode(sentences, convert_to_tensor=True)

# Load model and data
model = load_model()
df = load_data()
corpus = df[["‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö_‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì", "query1 ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Ñ‡∏£‡∏ö"].tolist()]
corpus_embeddings = embed_corpus(corpus)

# Streamlit UI
st.title("üçú Thai Food Search ")
query = st.text_input("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏ô‡∏π ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô:")

if query:
    query_embedding = model.encode(query, convert_to_tensor=True)
    scores = util.cos_sim(query_embedding, corpus_embeddings)[0]

    top_k = min(10, len(corpus))
    results = torch.topk(scores, k=top_k)

    st.subheader("üìå ‡πÄ‡∏°‡∏ô‡∏π‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
    for idx in results.indices:
        row = df.iloc[idx]
        st.markdown(f"""
        - **{row['th_name']}**
        - üßÇ **‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°:** {row.get('ingredients', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}
        - üè∑Ô∏è **‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà:** {row.get('category', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}
        """)
