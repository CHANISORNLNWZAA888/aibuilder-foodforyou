import streamlit as st
import pandas as pd
import requests
from PIL import Image
from io import BytesIO
from sentence_transformers import SentenceTransformer, util
import torch
import datetime
import pytz

# Secrets
HF_TOKEN = st.secrets["api"]["hf_token"]
GOOGLE_API_KEY = st.secrets["api"]["google_api_key"]
CSE_ID = st.secrets["api"]["cse_id"]

# Greeting
def get_time_greeting():
    tz = pytz.timezone("Asia/Bangkok")
    now = datetime.datetime.now(tz).time()
    if datetime.time(5, 0) <= now < datetime.time(12, 0):
        return "‚òÄÔ∏è ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ï‡∏≠‡∏ô‡πÄ‡∏ä‡πâ‡∏≤! ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ?"
    elif datetime.time(12, 0) <= now < datetime.time(17, 0):
        return "üå§Ô∏è ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ï‡∏≠‡∏ô‡∏ö‡πà‡∏≤‡∏¢! ‡∏´‡∏¥‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ?"
    elif datetime.time(17, 0) <= now < datetime.time(22, 0):
        return "üåá ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ï‡∏≠‡∏ô‡πÄ‡∏¢‡πá‡∏ô! ‡∏´‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡∏¥‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏ñ‡∏≠‡∏∞"
    else:
        return "üåô ‡∏î‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡πâ‡∏≤~ ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏´‡∏¥‡∏ß‡∏Å‡πá‡∏°‡∏≤‡∏´‡∏≤‡πÄ‡∏°‡∏ô‡∏π‡∏Å‡∏¥‡∏ô‡∏Å‡∏±‡∏ô!"

# Load models and data
@st.cache_resource
def load_search_model():
    return SentenceTransformer("Chanisorn/thai-food-mpnet-new-v8", use_auth_token=HF_TOKEN)

@st.cache_data
def load_data():
    df_main = pd.read_csv("thai_food_data.csv")
    df_recipe = pd.read_csv("recipe_original.csv")
    df_merged = pd.merge(df_main, df_recipe[["‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£", "‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥"]], on="‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£", how="left")
    return df_merged

@st.cache_resource
def embed_corpus(_model, texts):
    return _model.encode(texts, convert_to_tensor=True)

# Google image search
def google_image_search(query, num_images=1):
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "q": query,
        "cx": CSE_ID,
        "key": GOOGLE_API_KEY,
        "searchType": "image",
        "num": num_images
    }
    res = requests.get(url, params=params)
    data = res.json()
    if "items" in data:
        return [item["link"] for item in data["items"]]
    return []

def display_images(image_urls):
    for url in image_urls:
        try:
            st.markdown(
                f"""
                <div style='text-align: center;'>
                    <img src="{url}" style="width:80%; border-radius: 12px; margin-top: 10px;" />
                </div>
                """,
                unsafe_allow_html=True
            )
        except Exception:
            st.write("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ")

# Load all resources
search_model = load_search_model()
df = load_data()
corpus_texts = (df["‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö_‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì"].fillna("") + " " + df["query1 ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Ñ‡∏£‡∏ö"].fillna("")).tolist()
corpus_embeddings = embed_corpus(search_model, corpus_texts)

# UI styling and header
st.markdown("""
    <style>
        @keyframes rainbow {
            0% { color: red; }
            14% { color: orange; }
            28% { color: yellow; }
            42% { color: green; }
            57% { color: blue; }
            71% { color: indigo; }
            85% { color: violet; }
            100% { color: red; }
        }

        .rainbow-header {
            font-size: 45px;
            font-weight: bold;
            text-align: center;
            animation: rainbow 10s infinite;
            margin-top: 30px;
        }

        .sub-description {
            font-size: 18px;
            text-align: center;
            margin-top: 10px;
            color: #555;
        }

        .greeting {
            font-size: 28px;
            color: var(--text-color);
            text-align: center;
            animation: fadeIn 2s ease-in-out;
            margin-top: 30px;
            margin-bottom: 30px;
        }

        @keyframes fadeIn {
            0% { opacity: 0; transform: translateY(-10px); }
            100% { opacity: 1; transform: translateY(0); }
        }
    </style>

    <div class='rainbow-header'>Food for You</div>
    <div class='sub-description'>
        AI ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏à‡∏Ñ‡∏∏‡∏ì‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÉ‡∏ô‡∏ö‡πâ‡∏≤‡∏ô ‡πÉ‡∏™‡πà‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö‡πÉ‡∏ô‡∏ö‡πâ‡∏≤‡∏ô ‡∏Å‡πá‡∏û‡∏£‡πâ‡∏≠‡∏°!
    </div>
""", unsafe_allow_html=True)

# Greeting section
if "query_sent" not in st.session_state:
    st.session_state.query_sent = False

if not st.session_state.query_sent:
    greeting = get_time_greeting()
    st.markdown(f"<div class='greeting'>{greeting}</div>", unsafe_allow_html=True)

# Input section with examples
query = st.text_input(
    "‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô üëá",
    placeholder="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏°‡∏µ‡∏Å‡∏∏‡πâ‡∏á‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏ç‡πà‡πÜ ‡∏ï‡∏∞‡πÑ‡∏Ñ‡∏£‡πâ ‡πÉ‡∏ö‡∏°‡∏∞‡∏Å‡∏£‡∏π‡∏î ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡πÄ‡∏°‡∏ô‡∏π‡∏ô‡πâ‡∏≥ ‡πÑ‡∏Ç‡∏°‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢, ‡∏≠‡∏¢‡∏≤‡∏Å‡∏ó‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÇ‡∏ö‡∏£‡∏≤‡∏ì ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏´‡∏°‡∏π ‡∏Å‡∏∞‡∏ó‡∏¥ ‡πÉ‡∏ö‡πÇ‡∏´‡∏£‡∏∞‡∏û‡∏≤ ‡∏°‡∏∞‡πÄ‡∏Ç‡∏∑‡∏≠‡πÄ‡∏ó‡∏® ‡∏Å‡∏∏‡πâ‡∏á‡πÅ‡∏´‡πâ‡∏á"
)

if query:
    st.session_state.query_sent = True

    # Find similar dishes
    query_embedding = search_model.encode(query, convert_to_tensor=True)
    scores = util.cos_sim(query_embedding, corpus_embeddings)[0]
    top_k = min(3, len(df))
    results = torch.topk(scores, k=top_k)

    st.subheader("üìå ‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")

    for idx in results.indices:
        row = df.iloc[idx.item()]
        dish_name = row["‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£"]
        ingredients = row.get("‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö_‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        method = row.get("‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥", "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥")

        st.markdown(f"### üçΩÔ∏è {dish_name}")
        st.markdown(f"- üßÇ **‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°:** {ingredients}")
        st.markdown(f"- üç≥ **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥:** {method}")

        image_urls = google_image_search(dish_name, num_images=1)
        display_images(image_urls)

       


